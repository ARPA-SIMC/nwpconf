## @file
## @brief Module with generic functions for administering arkimet archives.

## @details This module provides functions for administering arkimet
## archives beyond what is done by the native arkimet tools.

## @fn arki_getdslist
## @brief get the list of datasets from a config file.
## @details this function prints on stdout the list of datasets
## contained in a server-wide config file (e.g. one generated by the
## `arki-mergeconf command`).
# @param $1 config file name
arki_getdslist() {
    sed -n -e '/^\[.*\]$/{s/\[\(.*\)\]/\1/g;p};' $1
}

## @fn arki_getdskey
## @brief get the content of a key from a config file.
## @details this function prints on stdout the content of a specific
## key for all the datasets contained in a config file.
# @param $1 config file name
# @param $2 key whose value should be printed for every dataset
arki_getdskey() {
#    sed -n -e '/^ *'$2' *=/{s/^ *'$2' *= *//;p};' $1
    sed -n -e "/^ *$2 *=/{s/^ *$2 *= *//;p};" $1
}

# @fn arki_dailycleanup
# @brief Perform the daily cleanup of a set of arkimet datasets.
# @details This function takes as an argument a collection of arkimet
# datasets (generated with the `arki-mergeconf` command) and performs
# the daily deletion of old data. If the two additional parameters
# `$2` and `$3` are provided, they are applied to every dataset of the
# config file; if the parameters are not provided, the deletion time
# is taken from the `delete age` parameter of each dataset, thus
# datasets without that parameter are not touched.
# @param $1 config file name
# @param $2 days in the past for starting deletion (optional)
# @param $3 days in the past for stopping deletion (optional)
arki_dailycleanup() {
    local dslist
    dslist=`arki_getdskey $1 path`
    for ds in $dslist; do
	if [ -n "$2" -a -n "$3" ]; then
	    s1=$2
	    s2=$3
	else
	    confage=`arki_getdskey $ds/config 'delete age'`
	    s1=0
	    s2=-1
	    if [ -n "$confage" ]; then
		s1=$confage
		s2=$(($confage + 8))
	    fi
	fi
#    arki_dev=`stat -c %D $ARKI_DIR`
	for back in `seq $s1 $s2`; do
            yy=`date -u --date "$back days ago" "+%Y"`
            mm=`date -u --date "$back days ago" "+%m"`
            dd=`date -u --date "$back days ago" "+%d"`

	    rm -f $ds/$yy/$mm-$dd.grib* $ds/$yy/$mm-$dd.bufr
#            if [ "`stat -c %D $file 2>/dev/null`" = "$arki_dev" ]; then
	done
    done
    arki-check --fix --config=$1 # --repack
}

# @fn arki_dailyarchivecleanup
# @brief Perform the daily cleanup of a set of arkimet datasets.
# @details This function takes as an argument a collection of arkimet
# datasets (generated with the `arki-mergeconf` command) and performs
# the daily deletion of old data. If the two additional parameters
# `$2` and `$3` are provided, they are applied to every dataset of the
# config file; if the parameters are not provided, the deletion time
# is taken from the `delete age` parameter of each dataset, thus
# datasets without that parameter are not touched.
# @param $1 config file name
# @param $2 archiving base directory
arki_dailyarchivecleanup() {
    local dslist
    dslist=`arki_getdskey $1 path`
    for ds in $dslist; do
	apath=$2/`basename $ds`
	confage=`arki_getdskey $ds/config 'delete age'`
	confaage=`arki_getdskey $ds/config 'archive age'`
	s1=0
	s2=-1
	if [ -n "$confage" ]; then
	    s1=$confage
	    s2=$(($confage + 8))
	fi
	s0=$s1
	if [ -n "$confaage" ]; then
	    s0=$confaage
	fi
	for back in `seq $s0 $(($s1 - 1))`; do
            yy=`date -u --date "$back days ago" "+%Y"`
            mm=`date -u --date "$back days ago" "+%m"`
            dd=`date -u --date "$back days ago" "+%d"`
	    mkdir -p $apath/$yy
	    for file in $ds/$yy/$mm-$dd.grib* $ds/$yy/$mm-$dd.bufr; do
		if [ -f "$file" -a ! -L "$file" ]; then
		    f=`basename $file`
		    mv $file $apath/$yy/$f
		    ln -s $apath/$yy/$f $file # $ds must be absolute path
		fi
	    done
	done
	for back in `seq $s1 $s2`; do
            yy=`date -u --date "$back days ago" "+%Y"`
            mm=`date -u --date "$back days ago" "+%m"`
            dd=`date -u --date "$back days ago" "+%d"`

	    for file in $ds/$yy/$mm-$dd.grib* $ds/$yy/$mm-$dd.bufr; do
		if [ -L "$file" ]; then
		    rm -f `readlink $file` $file
		elif [ -f "$file" ]; then # non-broken symlink satisfies -f too
		    rm -f $file
		fi
	    done
	done
    done
#    arki-check --fix --config=$1 # --repack
}


# @fn import_signal_setupdb
# @brief Initialise the import signal database.
# @details This function initialises the postgresql database for
# signaling the import of data into arkimet datasets. If `-f` argument
# is passed it erases all the existing data in the `imports` table and
# recreates it from zero, otherwise it fails if the table already
# exists. It uses the `psql` command, the authentication must be taken
# care of e.g. by means of a ~/.pgpass` file in the user's home
# directory.
# @param $1 `-f` for forcing the initialisation of the table if it already exists
import_signal_setupdb() {

if [ "$1" = -f ]; then
    pgsql_command <<EOF
DROP TABLE imports;
EOF
fi

pgsql_command <<EOF
CREATE TABLE imports (dataset varchar(128) NOT NULL,
 reftime timestamp without time zone NOT NULL,
 message varchar(128) DEFAULT NULL,
 importtime timestamp without time zone DEFAULT NULL,
 PRIMARY KEY (reftime, dataset, message));
EOF
}


# @fn import_signal_imported
# @brief Signal the import af a file into a dataset.
# @details This function .
# @param $1 dataset name
# @param $2 reference date and time of the data YYYYmmdd[HH[MM]]
# @param $3 additional unique name of the message imported (can be empty)
import_signal_imported() {
    local pgdate pgtime
    pgdate=${2:0:8}
    pgtime=${2:8:4}
# pad with zero hour/minutes
    if [ ${#pgtime} = 0 ]; then
	pgtime="0000"
    elif [ ${#pgtime} = 2 ]; then
	pgtime="${pgtime}00"
    fi

    case $IMPORT_SIGNAL_METHOD in
	psql)
	    pgsql_command <<EOF
INSERT INTO imports (dataset, reftime, message, importtime)
 SELECT '$1', '$pgdate $pgtime', '$3', 'now'
 WHERE NOT EXISTS(SELECT 1 FROM imports 
 WHERE dataset = '$1' AND reftime = '$pgdate $pgtime' AND message = '$3');
EOF
# update importtime if exists?
	    ;;
	curl)
 	    if [ "$3" = "*" ]; then
#	        url="imported/$1/$pgdate $pgtime"
		url="imported/$1/$2"
	    else
#	        url="imported/$1/$pgdate $pgtime/$3"
		url="imported/$1/$2/$3"
	    fi
	    curl $IMPORT_SIGNAL_ARGS "$IMPORT_SIGNAL_URL/$url"
	    ;;
    esac
}


import_signal_check() {
    local pgdate pgtime
    pgdate=${2:0:8}
    pgtime=${2:8:4}
# pad with zero hour/minutes
    if [ ${#pgtime} = 0 ]; then
	pgtime="0000"
    elif [ ${#pgtime} = 2 ]; then
	pgtime="${pgtime}00"
    fi

    case $IMPORT_SIGNAL_METHOD in
	psql)
# \set ON_ERROR_STOP on returns a status of 3 in case of query error
# e.g. wrong time syntax

 	    if [ "$3" = "*" ]; then
		pgsql_command <<EOF
\set ON_ERROR_STOP on
SELECT COUNT(*) FROM imports
 WHERE dataset = '$1' AND
 reftime = timestamp without time zone '$pgdate $pgtime';
EOF
	    else
		pgsql_command <<EOF
\set ON_ERROR_STOP on
SELECT COUNT(*) FROM imports
 WHERE dataset = '$1' AND
 reftime = timestamp without time zone '$pgdate $pgtime' AND message='$3';
EOF
	    fi
	    ;;
	curl)
 	    if [ "$3" = "*" ]; then
#	        url="check/$1/$pgdate $pgtime"
		url="check/$1/$2"
	    else
#	        url="check/$1/$pgdate $pgtime/$3"
		url="check/$1/$2/$3"
	    fi
	    curl $IMPORT_SIGNAL_ARGS "$IMPORT_SIGNAL_URL/$url" || echo 0
	    ;;
    esac    
}


import_signal_dailycleanup() {
    pgsql_command <<EOF
DELETE FROM imports WHERE
reftime < timestamp without time zone 'now' - interval '$1 day';
EOF
}


import_signal_wait() {
    local count mincount
    local initialtime=`date -u +%s`

    if [ -n "$4" ]; then
	mincount=$4
    else
	mincount=1	
    fi
# wait forever, improve?
    while true; do
	count=`import_signal_check "$1" "$2" "$3"`
	if [ "$count" -ge "$mincount" ]; then
	    return 0
	fi
	if [ -n "$GETARKI_WAITTOTAL" ]; then
	    if [ $((`date -u +%s` - $initialtime)) -gt "$GETARKI_WAITTOTAL" ]; then
		echo "Timeout reached, exiting"
		return 1
	    fi
	fi
	sleep $GETARKI_WAITSTART
    done
}


pgsql_command() {
    psql $IMPORT_SIGNAL_ARGS -A -F ',' -n -q -t
}


# start exporting all assignments
set -a
# checks
check_dep arki_tools
# stop exporting all assignments
set +a
