## @file
## @brief Module with generic functions for administering arkimet archives.

## @details This module provides functions for administering arkimet
## archives beyond what is done by the native arkimet tools.

## @fn arki_getdslist
## @brief get the list of datasets from a config file.
## @details this function prints on stdout the list of datasets
## contained in a server-wide config file (e.g. one generated by the
## `arki-mergeconf command`).
# @param $1 config file name
arki_getdslist() {
    sed -n -e '/^\[.*\]$/{s/\[\(.*\)\]/\1/g;p};' $1
}

## @fn arki_getdskey
## @brief get the content of a key from a config file.
## @details this function prints on stdout the content of a specific
## key for all the datasets contained in a config file.
# @param $1 config file name
# @param $2 key whose value should be printed for every dataset
arki_getdskey() {
#    sed -n -e '/^ *'$2' *=/{s/^ *'$2' *= *//;p};' $1
    sed -n -e "/^ *$2 *=/{s/^ *$2 *= *//;p};" $1
}

# @fn arki_dailycleanup
# @brief Perform the daily cleanup of a set of arkimet datasets.
# @details This function takes as an argument a collection of arkimet
# datasets (generated with the `arki-mergeconf` command) and performs
# the daily deletion of old data. If the two additional parameters
# `$2` and `$3` are provided, they are applied to every dataset of the
# config file; if the parameters are not provided, the deletion time
# is taken from the `delete age` parameter of each dataset, thus
# datasets without that parameter are not touched in that
# case. However in both cases, unlike arkimet's internal delete age
# mechanism, the dates to be cleaned are computed relatively to the
# suite date (`$DATE`) and not relatively to the current date.
# @param $1 config file name
# @param $2 days in the past for starting deletion (optional)
# @param $3 days in the past for stopping deletion (optional)
arki_dailycleanup() {
    local dslist
    dslist=`arki_getdskey $1 path`
    for ds in $dslist; do
	if [ -n "$2" -a -n "$3" ]; then
	    s1=$2
	    s2=$3
	else
	    confage=`arki_getdskey $ds/config 'delete age'`
	    s1=0
	    s2=-1
	    if [ -n "$confage" ]; then
		s1=$confage
		s2=$(($confage + 8))
	    fi
	fi
	for back in `seq $s1 $s2`; do
            yy=`date -u --date "$DATE $back days ago" "+%Y"`
            mm=`date -u --date "$DATE $back days ago" "+%m"`
            dd=`date -u --date "$DATE $back days ago" "+%d"`
# remove data and indices
	    rm -f $ds/$yy/$mm-$dd.*
	done
    done
}


# @fn import_signal_setupdb
# @brief Initialise the import signal database.
# @details This function initialises the postgresql database for
# signaling the import of data into arkimet datasets. If `-f` argument
# is passed it erases all the existing data in the `imports` table and
# recreates it from zero, otherwise it fails if the table already
# exists. It uses the `psql` command, the authentication must be taken
# care of e.g. by means of a ~/.pgpass` file in the user's home
# directory.
# @param $1 `-f` for forcing the initialisation of the table if it already exists
import_signal_setupdb() {

if [ "$1" = -f ]; then
    pgsql_command <<EOF
DROP TABLE imports;
EOF
fi

pgsql_command <<EOF
CREATE TABLE imports (dataset varchar(128) NOT NULL,
 reftime timestamp without time zone NOT NULL,
 message varchar(128) DEFAULT NULL,
 importtime timestamp without time zone DEFAULT NULL,
 PRIMARY KEY (reftime, dataset, message));
EOF
}


# @fn import_signal_imported
# @brief Signal the import af a file into a dataset.
# @details This function signals the end of import of a single file,
# indicated as third argument, or of a complete model run, if third
# argument is empty. It uses the signal method indicated by \a
# $IMPORT_SIGNAL_METHOD variable (e.g. psql, curl or filesystem).
# @param $1 dataset name
# @param $2 reference date and time of the data YYYYmmdd[HH[MM]]
# @param $3 additional unique name of the message/file imported (can be empty)
import_signal_imported() {
    local pgdate pgtime
    pgdate=${2:0:8}
    pgtime=${2:8:4}
# pad with zero hour/minutes
    if [ ${#pgtime} = 0 ]; then
	pgtime="0000"
    elif [ ${#pgtime} = 2 ]; then
	pgtime="${pgtime}00"
    fi

    case $IMPORT_SIGNAL_METHOD in
	psql)
	    pgsql_command <<EOF
INSERT INTO imports (dataset, reftime, message, importtime)
 SELECT '$1', '$pgdate $pgtime', '$3', 'now'
 WHERE NOT EXISTS(SELECT 1 FROM imports 
 WHERE dataset = '$1' AND reftime = '$pgdate $pgtime' AND message = '$3');
EOF
# update importtime if exists?
	    ;;
	curl)
 	    if [ "$3" = "*" -o -z "$3" ]; then
		url="imported/$1/$2"
	    else
		url="imported/$1/$2/$3"
	    fi
	    curl $IMPORT_SIGNAL_ARGS "$IMPORT_SIGNAL_URL/$url"
	    ;;
	filesystem)
	    mkdir -p  "$IMPORT_SIGNAL_BASE/$1/$pgdate$pgtime/"
 	    if [ "$3" = "*" -o -z "$3" ]; then
		touch "$IMPORT_SIGNAL_BASE/$1/$pgdate$pgtime/IMPORTED"
	    else
		touch "$IMPORT_SIGNAL_BASE/$1/$pgdate$pgtime/$3"
	    fi
	    ;;
    esac
}


import_signal_check() {
    local pgdate pgtime rest add_h DATE_NEXT_BUFR TIME_NEXT_BUFR
    pgdate=${2:0:8}
    pgtime=${2:8:4}

    # In case bufr frequency (defined by 'FREQ_FILE_BUFR') does not match the 
    # frequency of assimilation cycles, the first subsequent BUFR file is considered.
    if [ "$1" = "cnmc_bufr" ]; then
        if [ -z "$FREQ_FILE_BUFR" ]; then
            echo "Configuration variable FREQ_FILE_BUFR is not defined"
            exit 1
        fi

        rest=`expr $pgtime % $FREQ_FILE_BUFR || true`
        if [ $rest -ne 0 ]; then
            add_h=$(($FREQ_FILE_BUFR-$rest))
            DATE_NEXT_BUFR=`date_add $pgdate $pgtime $add_h`
            TIME_NEXT_BUFR=`time_add $pgdate $pgtime $add_h`
            pgdate=$DATE_NEXT_BUFR
            pgtime=$TIME_NEXT_BUFR
        fi
    fi

# pad with zero hour/minutes
    if [ ${#pgtime} = 0 ]; then
	pgtime="0000"
    elif [ ${#pgtime} = 2 ]; then
	pgtime="${pgtime}00"
    fi

    case $IMPORT_SIGNAL_METHOD in
	psql)
# \set ON_ERROR_STOP on returns a status of 3 in case of query error
# e.g. wrong time syntax

 	    if [ "$3" = "*" ]; then
		pgsql_command <<EOF
\set ON_ERROR_STOP on
SELECT COUNT(*) FROM imports
 WHERE dataset = '$1' AND
 reftime = timestamp without time zone '$pgdate $pgtime';
EOF
	    else
		pgsql_command <<EOF
\set ON_ERROR_STOP on
SELECT COUNT(*) FROM imports
 WHERE dataset = '$1' AND
 reftime = timestamp without time zone '$pgdate $pgtime' AND message='$3';
EOF
	    fi
	    ;;
	curl)
 	    if [ "$3" = "*" ]; then
#	        url="check/$1/$pgdate $pgtime"
#    		url="check/$1/$2"
            url="check/$1/${pgdate}${pgtime:0:2}"
	    else
#	        url="check/$1/$pgdate $pgtime/$3"
#   		url="check/$1/$2/$3"
            url="check/$1/${pgdate}${pgtime:0:2}/$3"
	    fi
	    curl $IMPORT_SIGNAL_ARGS "$IMPORT_SIGNAL_URL/$url" || echo 0
	    ;;
	simc)
	    if [ "$3" = "*" -o -z "$3" ]; then
		simc_check_logevent "$1" "$pgdate$pgtime"
	    else
		simc_check_logevent "$1" "$pgdate$pgtime" "$3"
	    fi
	    ;;
	filesystem)
 	    if [ "$3" = "*" ]; then
		ls -1 $IMPORT_SIGNAL_BASE/$1/$pgdate$pgtime/ 2>/dev/null | wc -l
 	    elif [ -z "$3" ]; then
		ls -1 $IMPORT_SIGNAL_BASE/$1/$pgdate$pgtime/IMPORTED 2>/dev/null | wc -l
	    else
		ls -1 $IMPORT_SIGNAL_BASE/$1/$pgdate$pgtime/$3 2>/dev/null | wc -l
	    fi
    esac    
}


# @fn import_signal_dailycleanup
# @brief Clean up the signal database from old messages.
# @details This function cleans up the signal database from messages
# older than the requested number of days. It uses the signal method
# indicated by \a $IMPORT_SIGNAL_METHOD variable (e.g. psql or
# filesystem).
# @param $1 number of days to keep in the database with respect to current date
import_signal_dailycleanup() {

    case $IMPORT_SIGNAL_METHOD in
	psql)
	    pgsql_command <<EOF
DELETE FROM imports WHERE
reftime < timestamp without time zone 'now' - interval '$1 day';
EOF
	    ;;
	filesystem)
	    dt=`date_now`
	    dt=`datetime_sub ${dt}00 $(($1 * 24))`00
	    pushd $IMPORT_SIGNAL_BASE > /dev/null
	    for ds in *; do
		if [ -d "$ds" ]; then
		    pushd $ds > /dev/null
		    for dts in *; do
			if [ -d "$dts" ]; then
			    if [ "$dts" -lt "$dt" ]; then
				safe_rm_rf $dts
			    fi
			fi
		    done
		    popd > /dev/null
		fi
	    done
	    popd > /dev/null
	    ;;
    esac

}


import_signal_wait() {
    local count mincount
    nwpwait_setup

    if [ -n "$4" ]; then
	mincount=$4
    else
	mincount=1	
    fi

    while true; do
	count=`import_signal_check "$1" "$2" "$3"`
	if [ "$count" -ge "$mincount" ]; then
	    return 0
	fi
	nwpwait_wait || return 1
    done
}


pgsql_command() {
    psql $IMPORT_SIGNAL_ARGS -A -F ',' -n -q -t
}


set_import_signal_method() {

# extend list


if [[ "$1" =~ http://arkimet.metarpa:8090/ ]]; then
    export IMPORT_SIGNAL_METHOD=simc
elif [[ "$1" =~ https?://[^/]*/ ]]; then
    export IMPORT_SIGNAL_METHOD=curl
else
    export IMPORT_SIGNAL_METHOD=filesystem
fi
}

# start exporting all assignments
#set -a
# checks
check_dep arki_tools
# stop exporting all assignments
#set +a
